# âš™ï¸ Data Engineering & Preprocessing

Data engineering is a crucial step in AI and machine learning, involving the preparation of raw data to ensure high-quality, structured, and optimized input for models. ğŸš€

![Data Engineering](../images/Data_Engineering.png)
---

## ğŸ—ï¸ 1. Data Collection & Cleaning
Data collection involves gathering data from various sources, while cleaning ensures that the data is usable.

### ğŸ“¥ 1.1 Data Collection Sources
- ğŸŒ **APIs**: Collecting real-time data from web services.
- ğŸ—„ï¸ **Databases**: SQL, NoSQL, and cloud-based data storage.
- ğŸ•· **Web Scraping**: Extracting data from websites using libraries like `BeautifulSoup` and `Scrapy`.
- ğŸ“¡ **Sensor Data**: IoT devices and real-time monitoring.

**Example: Web Scraping with BeautifulSoup** ğŸ“°
```python
import requests
from bs4 import BeautifulSoup

url = "https://example.com/news"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")
articles = soup.find_all("h2")
for article in articles:
    print(article.text)
```

### ğŸ§¹ 1.2 Data Cleaning
Cleaning involves handling inconsistent, incomplete, and duplicate data.

**Steps:**
âœ… Remove duplicates  
âœ… Handle missing values  
âœ… Standardize formatting  
âœ… Remove irrelevant data  

**Example: Cleaning a Pandas DataFrame** ğŸ—‚ï¸
```python
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', None], 'Age': [25, None, 30, 22]}
df = pd.DataFrame(data)

# Handle missing values
df.fillna({'Name': 'Unknown', 'Age': df['Age'].mean()}, inplace=True)
print(df)
```

---

## âš ï¸ 2. Handling Missing Data & Outliers

### ğŸ” 2.1 Handling Missing Data
Missing data can be handled using:
- ğŸ“Š **Mean/Median/Mode Imputation**
- â© **Forward/Backward Fill**
- ğŸ—‘ **Dropping Missing Values**

**Example: Using Mean Imputation**
```python
df['Age'].fillna(df['Age'].mean(), inplace=True)
```

### ğŸš¨ 2.2 Handling Outliers
Outliers can be detected and removed using:
- ğŸ“ **Z-score Method**
- ğŸ“ˆ **Interquartile Range (IQR)**
- ğŸ”„ **Winsorization**

**Example: Detecting Outliers with IQR**
```python
Q1 = df['Age'].quantile(0.25)
Q3 = df['Age'].quantile(0.75)
IQR = Q3 - Q1
outliers = df[(df['Age'] < (Q1 - 1.5 * IQR)) | (df['Age'] > (Q3 + 1.5 * IQR))]
print("Outliers:", outliers)
```

---

## ğŸ”¬ 3. Feature Engineering & Selection
Feature engineering creates meaningful features, while feature selection chooses the most relevant ones.

### ğŸ¨ 3.1 Feature Engineering
- ğŸ”¢ **Encoding Categorical Data** (One-Hot Encoding, Label Encoding)
- ğŸ“† **Date/Time Features** (Extracting Day, Month, Year, etc.)
- ğŸ› ï¸ **Domain-Specific Features** (Custom transformations)

**Example: One-Hot Encoding** ğŸ­
```python
from sklearn.preprocessing import OneHotEncoder
import numpy as np

X = np.array([['Red'], ['Blue'], ['Green']])
encoder = OneHotEncoder(sparse=False)
encoded_X = encoder.fit_transform(X)
print(encoded_X)
```

### ğŸ¯ 3.2 Feature Selection
- ğŸš **Filter Methods** (Correlation, Chi-Square Test)
- ğŸ” **Wrapper Methods** (Recursive Feature Elimination)
- ğŸŒ³ **Embedded Methods** (Lasso, Decision Trees)

**Example: Feature Selection using Lasso** ğŸ¯
```python
from sklearn.linear_model import Lasso
from sklearn.datasets import load_boston

boston = load_boston()
X, y = boston.data, boston.target
model = Lasso(alpha=0.1)
model.fit(X, y)
print("Selected Features:", model.coef_)
```

---

## ğŸ“ˆ 4. Data Augmentation
Data augmentation artificially increases the training dataset using transformations.

### ğŸ–¼ï¸ 4.1 Image Augmentation
```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2)
```

### ğŸ“ 4.2 Text Data Augmentation
```python
from nlpaug.augmenter.word import SynonymAug
aug = SynonymAug()
text = "AI is transforming the world."
print(aug.augment(text))
```

---

## ğŸ”„ 5. Building a Data Engineering Pipeline
A data engineering pipeline automates the flow of data from collection to preprocessing.

### ğŸ›  Steps:
1ï¸âƒ£ Data Ingestion  
2ï¸âƒ£ Data Cleaning & Transformation  
3ï¸âƒ£ Feature Engineering  
4ï¸âƒ£ Data Storage  
5ï¸âƒ£ Data Serving  

**Example: End-to-End Pipeline using Pandas** ğŸ”—
```python
def load_data():
    return pd.read_csv("data.csv")

def clean_data(df):
    df.drop_duplicates(inplace=True)
    df.fillna(df.mean(), inplace=True)
    return df

def transform_data(df):
    df['NewFeature'] = df['Age'] * 2  # Example feature engineering
    return df

def save_data(df):
    df.to_csv("processed_data.csv", index=False)

df = load_data()
df = clean_data(df)
df = transform_data(df)
save_data(df)
print("âœ… Pipeline executed successfully!")
```

---

## ğŸ† Conclusion
Data engineering is a crucial step in AI, ensuring that raw data is transformed into a structured format suitable for machine learning models. A well-designed data pipeline automates this process, improving efficiency and reproducibility. ğŸ”¥

ğŸ“– **[Back to Main README](../README.md)**
